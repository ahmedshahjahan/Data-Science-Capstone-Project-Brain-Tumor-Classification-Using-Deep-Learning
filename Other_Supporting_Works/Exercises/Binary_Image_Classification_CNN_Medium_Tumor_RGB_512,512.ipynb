{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import cv2\n",
    "import PIL\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# os.listdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = [\"./train_tumor/Tumor/\", \"./train_tumor1/NoTumor/\"]\n",
    "test_paths = [\"./test_tumor/Tumor/\", \"./test_tumor1/NoTumor/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing an saving the test images in same folder with same file name\n",
    "\n",
    "for path in training_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        f_img = path+img_name\n",
    "        img = Image.open(f_img)\n",
    "        try:\n",
    "            img = img.resize((512,512), Image.ANTIALIAS)\n",
    "            img.save(f_img, quality=95)\n",
    "        except ValueError:\n",
    "            print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing an saving the test images in same folder with same file name\n",
    "\n",
    "for path in test_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        f_img = path+img_name\n",
    "        img = Image.open(f_img)\n",
    "        try:\n",
    "            img = img.resize((512,512), Image.ANTIALIAS)\n",
    "            img.save(f_img, quality=95)\n",
    "        except ValueError:\n",
    "            print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 22 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train.flow_from_directory(\"train_tumor1\",\n",
    "                                          target_size=(512,512),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')\n",
    "                                         \n",
    "test_dataset = test.flow_from_directory(\"test_tumor1\",\n",
    "                                          target_size=(512,512),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NoTumor': 0, 'Tumor': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NoTumor': 0, 'Tumor': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# Convolutional layer and maxpool layer 1\n",
    "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(512,512,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 2\n",
    "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 3\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 4\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 1.1181 - accuracy: 0.5795 - val_loss: 0.4506 - val_accuracy: 0.9091\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.5346 - accuracy: 0.7045 - val_loss: 0.2880 - val_accuracy: 0.8182\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.2913 - accuracy: 0.8636 - val_loss: 0.4722 - val_accuracy: 0.8636\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.2202 - accuracy: 0.9205 - val_loss: 0.2957 - val_accuracy: 0.8409\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.1505 - accuracy: 0.9545 - val_loss: 0.3765 - val_accuracy: 0.8636\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0976 - accuracy: 0.9659 - val_loss: 0.4305 - val_accuracy: 0.8636\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.0690 - accuracy: 0.9773 - val_loss: 0.2876 - val_accuracy: 0.8636\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.8864\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9773\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 0.0142 - accuracy: 0.9886 - val_loss: 0.1471 - val_accuracy: 0.9318\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.8182\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 0.0424 - accuracy: 0.9659 - val_loss: 0.1403 - val_accuracy: 0.9545\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8864\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.8636\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.8636\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8636\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.8636\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 9.3934e-04 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.8636\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 4.4931e-04 - accuracy: 1.0000 - val_loss: 1.2028 - val_accuracy: 0.8636\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 7.6933e-05 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.8636\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 18s 6s/step - loss: 8.5484e-05 - accuracy: 1.0000 - val_loss: 1.6723 - val_accuracy: 0.8409\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 1.1960e-04 - accuracy: 1.0000 - val_loss: 1.8416 - val_accuracy: 0.8409\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 1.3365e-04 - accuracy: 1.0000 - val_loss: 1.9223 - val_accuracy: 0.8182\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 9.8689e-05 - accuracy: 1.0000 - val_loss: 1.9590 - val_accuracy: 0.8182\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 6.8976e-05 - accuracy: 1.0000 - val_loss: 1.9550 - val_accuracy: 0.8182\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 17s 6s/step - loss: 4.8467e-05 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.8409\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 16s 5s/step - loss: 2.6606e-05 - accuracy: 1.0000 - val_loss: 1.9032 - val_accuracy: 0.8409\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 1.6090e-05 - accuracy: 1.0000 - val_loss: 1.8801 - val_accuracy: 0.8636\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 18s 7s/step - loss: 1.1503e-05 - accuracy: 1.0000 - val_loss: 1.8590 - val_accuracy: 0.8636\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 16s 6s/step - loss: 8.6632e-06 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.8636\n",
      "489.60712003707886\n"
     ]
    }
   ],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         epochs = 10, batch_size=10,\n",
    "         validation_data = 0.0 \n",
    "         )\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 966ms/step - loss: 2.9465 - accuracy: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9465150833129883, 0.6363636255264282]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#steps_per_epoch = train_imagesize/batch_size\\n\\nmodel.fit_generator(train_dataset,\\n         steps_per_epoch = 250,\\n         epochs = 10,\\n         validation_data = test_dataset\\n       \\n         )\\n         \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "model.fit_generator(train_dataset,\n",
    "         steps_per_epoch = 250,\n",
    "         epochs = 10,\n",
    "         validation_data = test_dataset\n",
    "       \n",
    "         )\n",
    "         \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Manually Predicting \\ntest_path = \\'../test_tumor\\'\\nTumor=0\\nNoTumor=0\\nfor i in os.listdir(test_path):\\n    img = image.load_img(test_path + \"//\" +i, target_size=(512,512,3))\\n    plt.imshow(img)\\n    plt.show()\\n    X = image.img_to_array(img)\\n    X = np.expand_dims(X, axis=0)\\n    images = np.vstack([X])\\n    val = model.predict(images)\\n    if val == 0:\\n        NoTumor +=1\\n        print(\\'NoTumor\\')\\n    else:\\n        Tumor +=1\\n        print(\\'Tumor\\')\\nprint(f\\'Tumor: {Tumor}, NoTumor: {NoTumor}\\')\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Manually Predicting \n",
    "test_path = '../test_tumor'\n",
    "Tumor=0\n",
    "NoTumor=0\n",
    "for i in os.listdir(test_path):\n",
    "    img = image.load_img(test_path + \"//\" +i, target_size=(512,512,3))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    images = np.vstack([X])\n",
    "    val = model.predict(images)\n",
    "    if val == 0:\n",
    "        NoTumor +=1\n",
    "        print('NoTumor')\n",
    "    else:\n",
    "        Tumor +=1\n",
    "        print('Tumor')\n",
    "print(f'Tumor: {Tumor}, NoTumor: {NoTumor}')\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef predictImage(filename):\\n    img1 = image.load_img(filename,target_size=(224,224))\\n    \\n    plt.imshow(img1)\\n \\n    Y = image.img_to_array(img1)\\n    \\n    X = np.expand_dims(Y,axis=0)\\n    val = model.predict(X)\\n    print(val)\\n    if val == 1:\\n        \\n        plt.xlabel(\"Duck\",fontsize=20)\\n        \\n    \\n    elif val == 0:\\n        \\n        plt.xlabel(\"Bird\",fontsize=20)\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "def predictImage(filename):\n",
    "    img1 = image.load_img(filename,target_size=(224,224))\n",
    "    \n",
    "    plt.imshow(img1)\n",
    " \n",
    "    Y = image.img_to_array(img1)\n",
    "    \n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model.predict(X)\n",
    "    print(val)\n",
    "    if val == 1:\n",
    "        \n",
    "        plt.xlabel(\"Duck\",fontsize=20)\n",
    "        \n",
    "    \n",
    "    elif val == 0:\n",
    "        \n",
    "        plt.xlabel(\"Bird\",fontsize=20)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
