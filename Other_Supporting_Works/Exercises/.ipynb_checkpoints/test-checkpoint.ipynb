{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Sreenivas Bhattiprolu\"\n",
    "__license__ = \"Feel free to copy, I appreciate if you acknowledge Python for Microscopists\"\n",
    "\n",
    "\n",
    "# https://youtu.be/vF21cC-8G1U\n",
    "# https://youtu.be/Joh3LOaG8Q0\n",
    "\n",
    "\"\"\"\n",
    "Dataset from: https://lhncbc.nlm.nih.gov/publication/pub9932\n",
    "Binary problem:\n",
    "Question is: Is the image uninfected? If yes, probability is close to 1.\n",
    "If no, the probablility is close to 0.\n",
    "This is because we added label 1 to uninfected images. \n",
    "In summary, probability result close to 1 reflects uninfected image\n",
    "and close to 0 reflects parasitized image\n",
    "\"\"\"\n",
    "\n",
    "##########################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.style.use('classic')\n",
    "#############################################################\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "#from keras import backend as K\n",
    "####################################################\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_directory = 'cell_images/'\n",
    "SIZE = 150\n",
    "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
    "label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
    "\n",
    "parasitized_images = os.listdir(image_directory + 'Parasitized/')\n",
    "for i, image_name in enumerate(parasitized_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    \n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_directory + 'Parasitized/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "\n",
    "#Iterate through all images in Uninfected folder, resize to 64 x 64\n",
    "#Then save into the same numpy array 'dataset' but with label 1\n",
    "\n",
    "uninfected_images = os.listdir(image_directory + 'Uninfected/')\n",
    "for i, image_name in enumerate(uninfected_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_directory + 'Uninfected/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "label = np.array(label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)\n",
    "\n",
    "#Without scaling (normalize) the training may not converge. \n",
    "#Normalization is a rescaling of the data from the original range \n",
    "#so that all values are within the range of 0 and 1.\n",
    "from keras.utils import normalize\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n",
    "#Do not do one-hot encoding as it generates a shape of (num, 2)\n",
    "#But the network expects an input of (num, 1) for the last layer for binary classification\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)\n",
    "\n",
    "##############################################\n",
    "\n",
    "###2 conv and pool layers. with some normalization and drops in between.\n",
    "\n",
    "INPUT_SHAPE = (SIZE, SIZE, 3)   #change to (SIZE, SIZE, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))  \n",
    "#Do not use softmax for binary classification\n",
    "#Softmax is useful for mutually exclusive classes, either cat or dog but not both.\n",
    "#Also, softmax outputs all add to 1. So good for multi class problems where each\n",
    "#class is given a probability and all add to 1. Highest one wins. \n",
    "\n",
    "#Sigmoid outputs probability. Can be used for non-mutually exclusive problems.\n",
    "#But, also good for binary mutually exclusive (cat or not cat). \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',             #also try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())    \n",
    "###############################################################  \n",
    "\n",
    "##########################################################\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size = 64, \n",
    "                         verbose = 1, \n",
    "                         epochs = 10,      \n",
    "                         validation_data=(X_test,y_test),\n",
    "                         shuffle = False\n",
    "                     )\n",
    "\n",
    "\n",
    "model.save('malaria_model_10epochs.h5')  \n",
    "\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#########################################################################################\n",
    "#Test the model on one image (for 300 epochs)\n",
    "#img 23 is parasitized - correctly predicts near 0 probability\n",
    "#Img 22, parasitized, correctly lables (low value) but relatively high value.\n",
    "#img 24 is uninfected, correctly predicts as uninfected\n",
    "#img 26 is parasitized but incorrectly gives high value for prediction, uninfected.\n",
    "\n",
    "n=24  #Select the index of image to be loaded for testing\n",
    "img = X_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "print(\"The prediction for this image is: \", model.predict(input_img))\n",
    "print(\"The actual label for this image is: \", y_test[n])\n",
    "\n",
    "#Instead f checking for each image, we can evaluate the model on all test data\n",
    "#for accuracy\n",
    "################################################################\n",
    "\n",
    "#We can load the trained model, so we don't have to train again for 300 epochs!\n",
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('malaria_model.h5')\n",
    "\n",
    "#For 300 epochs, giving 82.5% accuracy\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "#How do we know how it is doing for parasitized vs uninfected? \n",
    "################################################################\n",
    "\n",
    "#Confusion matrix\n",
    "#We compare labels and plot them based on correct or wrong predictions.\n",
    "#Since sigmoid outputs probabilities we need to apply threshold to convert to label.\n",
    "\n",
    "mythreshold=0.908\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n",
    "cm=confusion_matrix(y_test, y_pred)  \n",
    "print(cm)\n",
    "\n",
    "#Check the confusion matrix for various thresholds. Which one is good?\n",
    "#Need to balance positive, negative, false positive and false negative. \n",
    "#ROC can help identify the right threshold.\n",
    "##################################################################\n",
    "\"\"\"\n",
    "Receiver Operating Characteristic (ROC) Curve is a plot that helps us \n",
    "visualize the performance of a binary classifier when the threshold is varied. \n",
    "\"\"\"\n",
    "#ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "y_preds = model.predict(X_test).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "#One way to find the best threshold once we calculate the true positive \n",
    "and false positive rates is ...\n",
    "The optimal cut off point would be where “true positive rate” is high \n",
    "and the “false positive rate” is low. \n",
    "Based on this logic let us find the threshold where tpr-(1-fpr) is zero (or close to 0)\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "i = np.arange(len(tpr)) \n",
    "roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\n",
    "ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n",
    "print(\"Ideal threshold is: \", ideal_roc_thresh['thresholds']) \n",
    "\n",
    "#Now use this threshold value in the confusion matrix to visualize the balance\n",
    "#between tp, fp, fp, and fn\n",
    "\n",
    "\n",
    "#AUC\n",
    "#Area under the curve (AUC) for ROC plot can be used to understand hpw well a classifier \n",
    "#is performing. \n",
    "#% chance that the model can distinguish between positive and negative classes.\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"Area under curve, AUC = \", auc_value)\n",
    "\n",
    "\n",
    "#########################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
