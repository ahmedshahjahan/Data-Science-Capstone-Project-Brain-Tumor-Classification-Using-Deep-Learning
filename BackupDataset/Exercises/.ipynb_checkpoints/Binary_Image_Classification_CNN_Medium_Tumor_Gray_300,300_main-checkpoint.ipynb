{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import cv2\n",
    "import PIL\n",
    "import time\n",
    "from skimage import color\n",
    "import os.path\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os, sys, os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, MaxPool2D, MaxPooling2D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# os.listdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = [\"./train_tumor/Tumor/\", \"./train_tumor/NoTumor/\"]\n",
    "validation_paths = [\"./validation_tumor/Tumor/\", \"./validation_tumor/NoTumor/\"]\n",
    "test_paths = [\"./test_tumor/Tumor/\", \"./test_tumor/NoTumor/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing an saving the training images in same folder with same file name\n",
    "\n",
    "for path in training_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        f_img = path+img_name\n",
    "        img = Image.open(f_img)\n",
    "        #img_gray = img.convert('L')\n",
    "        img_gray = ImageOps.grayscale(img)\n",
    "        try:\n",
    "            img_gray = img_gray.resize((300,300), PIL.Image.ANTIALIAS)\n",
    "            img_gray.save(f_img, quality=95)\n",
    "        except ValueError:\n",
    "            print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing an saving the training images in same folder with same file name\n",
    "\n",
    "for path in validation_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        f_img = path+img_name\n",
    "        img = Image.open(f_img)\n",
    "        #img_gray = img.convert('L')\n",
    "        img_gray = ImageOps.grayscale(img)\n",
    "        try:\n",
    "            img_gray = img_gray.resize((300,300), PIL.Image.ANTIALIAS)\n",
    "            img_gray.save(f_img, quality=95)\n",
    "        except ValueError:\n",
    "            print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing an saving the test images in same folder with same file name\n",
    "\n",
    "for path in test_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        f_img = path+img_name\n",
    "        img = Image.open(f_img)\n",
    "        #img_gray = img.convert('L')\n",
    "        img_gray = ImageOps.grayscale(img)\n",
    "        try:\n",
    "            img_gray = img_gray.resize((300,300), PIL.Image.ANTIALIAS)\n",
    "            img_gray.save(f_img, quality=95)\n",
    "        except ValueError:\n",
    "            print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 22 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train.flow_from_directory(\"train_tumor\",\n",
    "                                          target_size=(300,300),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary', color_mode=\"grayscale\")\n",
    "\n",
    "validation_dataset = train.flow_from_directory(\"validation_tumor\",\n",
    "                                          target_size=(300,300),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary', color_mode=\"grayscale\")\n",
    "\n",
    "test_dataset = test.flow_from_directory(\"test_tumor\",\n",
    "                                          target_size=(300,300),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'binary', color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NoTumor': 0, 'Tumor': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NoTumor': 0, 'Tumor': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NoTumor': 0, 'Tumor': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# Convolutional layer and maxpool layer 1\n",
    "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(300,300,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 2\n",
    "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 3\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 4\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.7380 - accuracy: 0.4773 - val_loss: 0.4495 - val_accuracy: 0.8409\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.4425 - accuracy: 0.8295 - val_loss: 0.3034 - val_accuracy: 0.8182\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.3324 - accuracy: 0.8523 - val_loss: 0.5935 - val_accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.2519 - accuracy: 0.9091 - val_loss: 0.3229 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.2105 - accuracy: 0.9318 - val_loss: 0.3192 - val_accuracy: 0.8636\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.1783 - accuracy: 0.9432 - val_loss: 0.3985 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.1408 - accuracy: 0.9545 - val_loss: 0.2882 - val_accuracy: 0.8636\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 10s 4s/step - loss: 0.1367 - accuracy: 0.9659 - val_loss: 0.2659 - val_accuracy: 0.8864\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0764 - accuracy: 0.9659 - val_loss: 0.3995 - val_accuracy: 0.8636\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0539 - accuracy: 0.9773 - val_loss: 0.2159 - val_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 0.1833 - val_accuracy: 0.9318\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0249 - accuracy: 0.9886 - val_loss: 0.6628 - val_accuracy: 0.8864\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.9091\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0133 - accuracy: 0.9886 - val_loss: 0.3909 - val_accuracy: 0.9318\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.9091\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.8864\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 10s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8864\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 7.1643e-04 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 3.1397e-04 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9091\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.9445e-04 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9318\n",
      "220.493066072464\n"
     ]
    }
   ],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         epochs = 20, batch_size=10,\n",
    "         validation_data = validation_dataset  \n",
    "         )\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 617ms/step - loss: 0.1529 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15294446051120758, 0.9090909361839294]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "# Convolutional layer, Batch Normalization layer, and maxpool layer 1\n",
    "model3.add(Conv2D(32,(3,3),activation='relu',input_shape=(300,300,1)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 2\n",
    "model3.add(Conv2D(64,(3,3),activation='relu'))\n",
    "# model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 3\n",
    "model3.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 4\n",
    "model3.add(Conv2D(256,(3,3),activation='relu'))\n",
    "# model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model3.add(Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model3.add(Dense(512,activation='relu'))\n",
    "# model3.add(Dropout(0.25))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model3.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3/3 [==============================] - 8s 3s/step - loss: 41.7471 - accuracy: 0.5682 - val_loss: 0.6768 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 7s 3s/step - loss: 14.9527 - accuracy: 0.5909 - val_loss: 0.6549 - val_accuracy: 0.6591\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 8s 3s/step - loss: 2.0088 - accuracy: 0.8977 - val_loss: 0.7205 - val_accuracy: 0.5000\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 7s 3s/step - loss: 1.9014 - accuracy: 0.9091 - val_loss: 1.0101 - val_accuracy: 0.5000\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 7s 3s/step - loss: 1.1662 - accuracy: 0.9432 - val_loss: 1.3005 - val_accuracy: 0.5000\n",
      "37.89298748970032\n"
     ]
    }
   ],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model3.fit(train_dataset, epochs = 25, batch_size=32, validation_data = validation_dataset, callbacks = [early_stopping_monitor])\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_300)\n",
    "print(np.mean(model_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "result = 0\n",
    "model_300 = []\n",
    "start = time.time()\n",
    "for i in range(3):\n",
    "    model.fit(train_dataset,\n",
    "             epochs = 5, batch_size=10,\n",
    "             validation_data = 0.0  \n",
    "             )\n",
    "    result = model.evaluate(test_dataset)\n",
    "    model_300.append(result[1])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model file\n",
    "import pickle\n",
    "pickle.dump(result, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model file again\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting model file\n",
    "print(type(pickle_model))\n",
    "print(pickle_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting single image\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (300, 300, 1))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "\n",
    "image = load('./test_tumor4/Tumor/Tr-me_0076.jpg')\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting single image\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (300, 300, 1))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "\n",
    "image = load('./test_tumor4/NoTumor/Tr-no_0054.jpg')\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = os.listdir(\"./train_tumor4/Tumor/\")\n",
    "rgb = plt.imread('./train_tumor4/Tumor/Tr-me_0010.jpg')\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "model.fit_generator(train_dataset,\n",
    "         steps_per_epoch = 250,\n",
    "         epochs = 10,\n",
    "         validation_data = test_dataset\n",
    "       \n",
    "         )\n",
    "         \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Manually Predicting \n",
    "test_path = '../test_tumor'\n",
    "Tumor=0\n",
    "NoTumor=0\n",
    "for i in os.listdir(test_path):\n",
    "    img = image.load_img(test_path + \"//\" +i, target_size=(512,512,3))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    images = np.vstack([X])\n",
    "    val = model.predict(images)\n",
    "    if val == 0:\n",
    "        NoTumor +=1\n",
    "        print('NoTumor')\n",
    "    else:\n",
    "        Tumor +=1\n",
    "        print('Tumor')\n",
    "print(f'Tumor: {Tumor}, NoTumor: {NoTumor}')\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
