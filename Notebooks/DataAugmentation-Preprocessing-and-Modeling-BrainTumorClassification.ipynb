{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling (Brain Tumor Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os, sys, os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, MaxPool2D, MaxPooling2D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generating the training, test, and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4923 images belonging to 4 classes.\n",
      "Found 1050 images belonging to 4 classes.\n",
      "Found 1050 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating Dataset using ImageDataGenerator\n",
    "# Using Resized and Cleaned Dataset\n",
    "# From \"../BrainTumorDataClean/\" directory\n",
    "\n",
    "#train = ImageDataGenerator(rescale=1/255)\n",
    "#test = ImageDataGenerator(rescale=1/255)\n",
    "#validation = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train = ImageDataGenerator(rescale=1/255, horizontal_flip=True)\n",
    "\n",
    "test = ImageDataGenerator(rescale=1/255, horizontal_flip=True) \n",
    "\n",
    "validation = ImageDataGenerator(rescale=1/255, horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_dataset = train.flow_from_directory(\"../BrainTumorDataClean/Training\",\n",
    "                                          target_size=(128,128),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "\n",
    "validation_dataset = validation.flow_from_directory(\"../BrainTumorDataClean/Validation\",\n",
    "                                          target_size=(128,128),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "\n",
    "test_dataset = test.flow_from_directory(\"../BrainTumorDataClean/Testing\",\n",
    "                                          target_size=(128,128),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 2, 0, 1, 2, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label =next(test_dataset)\n",
    "np.argmax(label[:10], axis=-1)\n",
    "#for i, j in zip(img, label):\n",
    "#     print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Implementing a Simple Neural Network using  dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the Simple model using Dense Layer [optimizer = 'adam']\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Flatten(input_shape=(128,128,1)))\n",
    "\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "\n",
    "model1.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with learning_rate=0.001\n",
    "early_stopping_monitor1 = EarlyStopping(patience=4)\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "154/154 [==============================] - 14s 83ms/step - loss: 1.0381 - accuracy: 0.5168 - val_loss: 0.8471 - val_accuracy: 0.6457\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 11s 73ms/step - loss: 0.7468 - accuracy: 0.6778 - val_loss: 0.7896 - val_accuracy: 0.6952\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 12s 75ms/step - loss: 0.6465 - accuracy: 0.7280 - val_loss: 0.7004 - val_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 12s 78ms/step - loss: 0.5755 - accuracy: 0.7634 - val_loss: 0.5844 - val_accuracy: 0.7733\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 12s 79ms/step - loss: 0.4973 - accuracy: 0.7981 - val_loss: 0.5340 - val_accuracy: 0.7933\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 12s 79ms/step - loss: 0.4593 - accuracy: 0.8135 - val_loss: 0.6435 - val_accuracy: 0.7914\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 11s 71ms/step - loss: 0.4073 - accuracy: 0.8395 - val_loss: 0.4695 - val_accuracy: 0.8114\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 8s 54ms/step - loss: 0.3737 - accuracy: 0.8556 - val_loss: 0.5693 - val_accuracy: 0.7895\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 6s 42ms/step - loss: 0.3483 - accuracy: 0.8655 - val_loss: 0.5465 - val_accuracy: 0.7781\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.3146 - accuracy: 0.8743 - val_loss: 0.4114 - val_accuracy: 0.8476\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.2813 - accuracy: 0.8871 - val_loss: 0.4473 - val_accuracy: 0.8581\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.2473 - accuracy: 0.9070 - val_loss: 0.3986 - val_accuracy: 0.8762\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 6s 41ms/step - loss: 0.2815 - accuracy: 0.8927 - val_loss: 0.3648 - val_accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.1973 - accuracy: 0.9234 - val_loss: 0.3884 - val_accuracy: 0.8819\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.2012 - accuracy: 0.9228 - val_loss: 0.3876 - val_accuracy: 0.8943\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 6s 42ms/step - loss: 0.2037 - accuracy: 0.9257 - val_loss: 0.3529 - val_accuracy: 0.8876\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 7s 43ms/step - loss: 0.1562 - accuracy: 0.9447 - val_loss: 0.4251 - val_accuracy: 0.8648\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 7s 43ms/step - loss: 0.1567 - accuracy: 0.9391 - val_loss: 0.3861 - val_accuracy: 0.8924\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 6s 41ms/step - loss: 0.1321 - accuracy: 0.9535 - val_loss: 0.3512 - val_accuracy: 0.8943\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 7s 42ms/step - loss: 0.1090 - accuracy: 0.9604 - val_loss: 0.3755 - val_accuracy: 0.9029\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history1 = model1.fit(train_dataset, epochs = 20, batch_size=32, \\\n",
    "                      validation_data = validation_dataset, callbacks=[early_stopping_monitor1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 16ms/step - loss: 0.2600 - accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25996923446655273, 0.9257143139839172]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.11055261e-08, 8.93206219e-04, 1.54247864e-05, 9.99091268e-01],\n",
       "       [9.99260128e-01, 4.57582733e-04, 5.59456612e-06, 2.76698731e-04],\n",
       "       [2.49504298e-02, 7.24840283e-01, 2.43843362e-01, 6.36591762e-03],\n",
       "       [4.27698083e-02, 9.56896901e-01, 2.86643801e-04, 4.66278652e-05],\n",
       "       [9.18086112e-01, 8.16188753e-02, 6.31110452e-05, 2.31876838e-04],\n",
       "       [5.31767844e-04, 3.01285461e-02, 9.68604147e-01, 7.35535868e-04],\n",
       "       [2.99326796e-02, 2.95317978e-01, 1.22391477e-01, 5.52357852e-01],\n",
       "       [9.94538486e-01, 4.66905348e-03, 1.84596851e-04, 6.07838971e-04],\n",
       "       [1.43615844e-05, 6.66349847e-03, 9.93300676e-01, 2.14918164e-05],\n",
       "       [1.02169015e-01, 8.97666395e-01, 1.43301455e-04, 2.13151616e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(predictions1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 1, 0, 2, 3, 0, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 0, 0, 3,\n",
       "       0, 1, 3, 3, 0, 2, 2, 2, 3, 3, 0, 3, 0, 3, 2, 0, 1, 2, 3, 2, 1, 3,\n",
       "       1, 1, 2, 1, 3, 0, 0, 3, 2, 2, 2, 3, 2, 3, 0, 2, 3, 0, 1, 0, 2, 3,\n",
       "       0, 3, 2, 0, 3, 1, 3, 3, 1, 1, 0, 2, 3, 2, 0, 2, 1, 3, 3, 1, 1, 2,\n",
       "       2, 3, 3, 0, 1, 1, 1, 2, 3, 3, 2, 1, 2, 0, 1, 3, 0, 0, 2, 1, 0, 2,\n",
       "       0, 0, 1, 2, 1, 2, 3, 1, 2, 2, 0, 3, 3, 3, 3, 3, 3, 2, 0, 0, 3, 2,\n",
       "       2, 3, 1, 1, 1, 1, 2, 1, 0, 0, 3, 0, 3, 0, 2, 0, 3, 1, 1, 2, 0, 2,\n",
       "       3, 2, 2, 1, 0, 2, 0, 0, 2, 2, 3, 0, 2, 2, 1, 0, 2, 2, 3, 0, 3, 2,\n",
       "       3, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2, 0, 1, 2, 3, 2, 2, 2, 1, 2, 1, 3,\n",
       "       2, 2, 1, 0, 0, 2, 0, 1, 1, 2, 2, 1, 1, 1, 0, 3, 0, 1, 1, 2, 1, 3,\n",
       "       3, 2, 1, 3, 0, 3, 0, 0, 0, 0, 2, 3, 2, 2, 0, 2, 2, 1, 1, 3, 0, 0,\n",
       "       2, 0, 2, 3, 2, 0, 0, 0, 0, 2, 0, 1, 3, 1, 0, 0, 2, 3, 0, 2, 2, 0,\n",
       "       3, 0, 2, 1, 0, 2, 2, 3, 3, 2, 0, 3, 0, 0, 2, 2, 1, 2, 2, 2, 2, 3,\n",
       "       2, 3, 1, 1, 2, 2, 0, 3, 3, 0, 1, 2, 1, 1, 1, 2, 3, 1, 2, 2, 1, 2,\n",
       "       1, 0, 2, 2, 1, 2, 0, 2, 3, 1, 3, 1, 2, 3, 2, 0, 2, 2, 3, 0, 3, 0,\n",
       "       2, 3, 0, 2, 3, 1, 2, 2, 0, 3, 2, 2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 0,\n",
       "       3, 1, 3, 3, 2, 2, 0, 1, 0, 2, 3, 2, 3, 1, 3, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 0, 3, 2, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 3, 1, 1, 3, 1,\n",
       "       0, 1, 2, 3, 0, 1, 3, 3, 3, 1, 1, 3, 0, 3, 1, 1, 2, 2, 2, 1, 2, 2,\n",
       "       0, 1, 0, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 2, 3, 3, 2, 2, 0, 1, 3,\n",
       "       2, 1, 2, 3, 1, 1, 0, 3, 2, 1, 2, 0, 0, 3, 2, 3, 2, 3, 3, 2, 2, 2,\n",
       "       2, 1, 0, 3, 2, 2, 2, 3, 2, 2, 3, 1, 1, 3, 2, 3, 0, 0, 0, 0, 2, 0,\n",
       "       2, 1, 0, 1, 3, 3, 0, 3, 0, 0, 1, 0, 1, 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.argmax(test_dataset.labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (Implementing a Simple Convolutional Neural Network Model Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(128,128,1)))\n",
    "model2.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model2.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model2.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor2 = EarlyStopping(patience=4)\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_dataset, steps_per_epoch=4923//32, validation_data=validation_dataset,\\\n",
    "           validation_steps=len(validation_dataset)//32, epochs=20, callbacks = [early_stopping_monitor2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 =model2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Historical LeNet-5 Architecture\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(20, (5,5), activation='relu', padding = 'same', strides=1, input_shape = (128,128,1)))\n",
    "model3.add(MaxPool2D((2,2), strides=2))\n",
    "\n",
    "model3.add(Conv2D(50, (5,5), activation='relu', strides=1, padding = 'same'))\n",
    "model3.add(MaxPool2D((2,2), strides=2))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "\n",
    "model3.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model3.fit(train_dataset, epochs = 20, batch_size=10, \\\n",
    "                      validation_data = validation_dataset, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = model3.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96.95%\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model4.add(Conv2D(32,(3,3), input_shape=(128,128,1), activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model4.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "# Neural network\n",
    "\n",
    "model4.add(Dense(units= 252, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(units=252, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model4.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics= ['categorical_accuracy'])\n",
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model6.fit(train_dataset, steps_per_epoch=4923//32, epochs=20, validation_data=validation_dataset, validation_steps= 1050//32,\n",
    "                     callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = model4.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 Implementing complex CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "model5 = Sequential()\n",
    "\n",
    "# Convolutional layer, Batch Normalization layer, and maxpool layer 1\n",
    "model5.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,1)))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 2\n",
    "model5.add(Conv2D(64,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 3\n",
    "model5.add(Conv2D(128,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 4\n",
    "model5.add(Conv2D(256,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model5.add(Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model5.add(Dense(512,activation='relu'))\n",
    "# model5.add(Dropout(0.25))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model5.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "model5.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "model5.fit(train_dataset, epochs = 20, batch_size=32, validation_data = validation_dataset, \\\n",
    "           callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5 = model5.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model6.add(Conv2D(64,(7,7), input_shape=(128,128, 1), padding='same', activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Convolutional layer 2\n",
    "model6.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model6.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 4\n",
    "model6.add(Conv2D(512,(7,7), padding='same', activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model6.add(Flatten())\n",
    "\n",
    "# Full connect layers\n",
    "\n",
    "model6.add(Dense(units= 512, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "model6.add(Dense(units=512, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "model6.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model6.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics= ['categorical_accuracy'])\n",
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model6.fit(train_dataset, steps_per_epoch=4923//32, epochs=20, validation_data=validation_dataset, validation_steps= 1050//32,\n",
    "                     callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5 =model5.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Models Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset, validation_dataset, test_dataset\n",
    "model1, history1, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test_new = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predictions2, axis=-1)\n",
    "y_true = test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred.shape\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true.shape\n",
    "y_true[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(14,7))\n",
    "sns.heatmap(confusion_matrix(y_true,Y_pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\n",
    "fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "# type(history1)\n",
    "# history1.history.items()\n",
    "plt.plot(history1.history['loss'], 'b', label='training loss')\n",
    "plt.plot(history1.history['val_loss'], 'r', label='validation loss')\n",
    "plt.xlabel('Epochs', )\n",
    "plt.ylabel('Validation score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_dataset.classes, y_pred=np.argmax(predictions1, axis=-1))\n",
    "cm_plot_labels = ['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 58  51  74  58]\n",
      " [ 49  52  95  49]\n",
      " [ 77  62 106  80]\n",
      " [ 44  53  83  59]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/2607\n",
    "test_generator = ImageDataGenerator()\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    test_data_path, # Put your path here\n",
    "     target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = numpy.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['Glioma','Meningioma','NoTumor','Pituitary']\n",
    "def get_all_metrics(y_true, y_pred, model_num, history):\n",
    "    \"\"\"\n",
    "    Confusion matrix and model performance metric visualization\n",
    "    \"\"\"\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    print(f\"\\nMax. training accuracy for {model_num}: {max(history1.history['accuracy'])*100:.2f}%\")\n",
    "    print(f\"Max. validation accuracy for {model_num}: {max(history1.history['val_accuracy'])*100:.2f}%\")\n",
    "    accuracy = np.sum(y_true == y_pred)/len(y_true)\n",
    "    print(f\"Test accuracy for {model_num}: {(accuracy*100):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nClassification Report for {model_num}:\\n\\n\", classification_report(y_true, y_pred))\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(16,8))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=\"Greens\",alpha=0.7,linewidths=2,linecolor='gray',fmt='d')\n",
    "    fig.text(s=f'      Confusion Matrix for {model_num}',size=18,fontweight='bold',\n",
    "            fontname='monospace',color='g',y=0.92,x=0.28,alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test, y_pred1, 'model_1', history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "from keras.models import model_from_json\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for keras nodel\n",
    "train_img = []\n",
    "train_labels = []\n",
    "\n",
    "test_img = []\n",
    "test_labels = []\n",
    "\n",
    "path_train = ('/kaggle/input/brain-tumor-classification-mri/Training/')\n",
    "path_test = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\n",
    "img_size= 300\n",
    "\n",
    "for i in os.listdir(path_train):\n",
    "    for j in os.listdir(path_train+i):\n",
    "        train_img.append (cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size))) \n",
    "        train_labels.append(i)\n",
    "        \n",
    "for i in os.listdir(path_test):\n",
    "    for j in os.listdir(path_test+i):\n",
    "        test_img.append (cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size))) \n",
    "        test_labels.append(i)\n",
    "        \n",
    "train_img = (np.array(train_img))\n",
    "test_img = (np.array(test_img))\n",
    "train_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(train_labels)]\n",
    "test_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "result = 0\n",
    "model_evaluate = []\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    model.fit(train_dataset,\n",
    "             epochs = 10, batch_size=10,\n",
    "             validation_data = 0.0  \n",
    "             )\n",
    "    result = model.evaluate(test_dataset)\n",
    "    model_evaluate.append(result[1])\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "model = effnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "model = ...\n",
    "\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)  # using comic sans is strictly prohibited!\n",
    "visualkeras.layered_view(model, legend=True, font=font)  # font is optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/visualkeras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "'''\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "'''\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Individual predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/OIP.jpg', target_size = (512, 512)) # Cargamos la imagen con un tamaño igual a\n",
    "                                                                                           # los anteriores\n",
    "test_image = image.img_to_array(test_image) # Convertimos la imagen en un array\n",
    "test_image = np.expand_dims(test_image, axis = 0) # Modificamos las dimensions\n",
    "result = classifier.predict(test_image) # Prediccion\n",
    "print(training_dataset.class_indices)\n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "'''\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary 1: horizontalflip=True, (64,64)\n",
    "model 1=0.88 , model2=0.9419, model3=0.9695, model4=0.9771, model5=0.9629, model6=0.9695\n",
    "Summary 2: (64,64)\n",
    "model 1=0.8990 , model2=0.9333, model3=0.9600, model4=0.9610, model5=, model6=0.9533\n",
    "Summary 3: horizontalflip=True, (128,128)\n",
    "model 1=0.84 , model2=0.9162, model3=0.9790, model4=0.9657, model5=, model6=0.9552\n",
    "Summary 4: (128,128)\n",
    "model 1=0.92 , model2=0.9467, model3=0.9638, model4=0.8971, model5=, model6=0.9457"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
