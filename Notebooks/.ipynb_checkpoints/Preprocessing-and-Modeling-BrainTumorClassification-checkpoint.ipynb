{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling (Brain Tumor Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, MaxPool2D, MaxPooling2D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "import time\n",
    "import os, sys, os.path\n",
    "from PIL import Image, ImageOps\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import color\n",
    "from skimage.filters import gaussian\n",
    "import cv2, PIL\n",
    "import itertools\n",
    "from IPython.display import display,clear_output\n",
    "from warnings import filterwarnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"../BrainTumorDataClean/Training/\"\n",
    "validation_path = \"../BrainTumorDataClean/Validation/\"\n",
    "test_path = \"../BrainTumorDataClean/Testing/\"\n",
    "\n",
    "labels = ['Glioma','Meningioma','NoTumor','Pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1145/1145 [00:00<00:00, 2784.96it/s]\n",
      "100%|██████████| 1163/1163 [00:00<00:00, 2969.92it/s]\n",
      "100%|██████████| 1361/1361 [00:00<00:00, 2581.46it/s]\n",
      "100%|██████████| 1254/1254 [00:00<00:00, 2780.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 128\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(training_path, i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = plt.imread(os.path.join(folderPath,j))\n",
    "        # img = cv2.resize(img,(image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:00<00:00, 2638.18it/s]\n",
      "100%|██████████| 237/237 [00:00<00:00, 2780.31it/s]\n",
      "100%|██████████| 314/314 [00:00<00:00, 2525.53it/s]\n",
      "100%|██████████| 264/264 [00:00<00:00, 2537.94it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid = []\n",
    "y_valid = []\n",
    "image_size = 128\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(validation_path, i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = plt.imread(os.path.join(folderPath,j))\n",
    "        # img = cv2.resize(img,(image_size, image_size))\n",
    "        X_valid.append(img)\n",
    "        y_valid.append(i)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:00<00:00, 2334.93it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 2512.01it/s]\n",
      "100%|██████████| 325/325 [00:00<00:00, 2445.40it/s]\n",
      "100%|██████████| 239/239 [00:00<00:00, 2388.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "image_size = 128\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(test_path, i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = plt.imread(os.path.join(folderPath,j))\n",
    "        # img = cv2.resize(img,(image_size, image_size))\n",
    "        X_test.append(img)\n",
    "        y_test.append(i)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = shuffle(X_valid, y_valid, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = shuffle(X_test, y_test, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4923, 128, 128), (1050, 128, 128), (1050, 128, 128))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4923,), (1050,), (1050,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pituitary', 'NoTumor', 'Meningioma', 'Meningioma', 'NoTumor',\n",
       "       'Meningioma', 'Meningioma', 'Pituitary', 'NoTumor', 'Pituitary',\n",
       "       'NoTumor', 'Pituitary', 'Glioma', 'NoTumor', 'NoTumor',\n",
       "       'Meningioma', 'Meningioma', 'NoTumor', 'NoTumor', 'Meningioma'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.index('NoTumor')\n",
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding to the image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_new = []\n",
    "for i in y_test:\n",
    "    y_valid_new.append(labels.index(i))\n",
    "y_valid = y_valid_new\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of y_test\n",
    "y_test1 = y_test\n",
    "y_test2 = y_test\n",
    "y_test3 = y_test\n",
    "y_test4 = y_test\n",
    "y_test5 = y_test\n",
    "y_test6 = y_test\n",
    "y_test7 = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4923, 4), (1050, 4), (1050, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10], y_valid[:10], y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Implementing a Simple Neural Network using  dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the Simple model using Dense Layer [optimizer = 'adam']\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Flatten(input_shape=(128,128,1)))\n",
    "\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "\n",
    "model1.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with learning_rate=0.001\n",
    "early_stopping_monitor1 = EarlyStopping(patience=5)\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "checkpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)\n",
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, min_denta=0.0001, mode='auto', verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "checkpoint = ModelCheckpoint(\"brain_tumor_classification.h5\", monitor='val_accuracy', save_best_only=True, mode='auto', verbose=1)\n",
    "history = model.fit(X_train, Y_train, batch_size=32,\n",
    "                              validation_data=(X_val, Y_val), \n",
    "                              epochs=30, m\n",
    "                              verbose=1,\n",
    "                            callbacks=[tensorboard, checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 44ms/step - loss: 31.7968 - accuracy: 0.4867 - val_loss: 11.7753 - val_accuracy: 0.5248\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 7s 43ms/step - loss: 3.4656 - accuracy: 0.6736 - val_loss: 3.8275 - val_accuracy: 0.7086\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 6s 39ms/step - loss: 1.9406 - accuracy: 0.7319 - val_loss: 3.0783 - val_accuracy: 0.6886\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 6s 39ms/step - loss: 1.4287 - accuracy: 0.7617 - val_loss: 3.4107 - val_accuracy: 0.6295\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 7s 43ms/step - loss: 0.9702 - accuracy: 0.7924 - val_loss: 2.1310 - val_accuracy: 0.6762\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 7s 43ms/step - loss: 0.7792 - accuracy: 0.8113 - val_loss: 1.5859 - val_accuracy: 0.7743\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 6s 38ms/step - loss: 0.6026 - accuracy: 0.8357 - val_loss: 1.7679 - val_accuracy: 0.7352\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 6s 41ms/step - loss: 0.4890 - accuracy: 0.8527 - val_loss: 1.3894 - val_accuracy: 0.7581\n",
      "Epoch 9/30\n",
      "154/154 [==============================] - 6s 39ms/step - loss: 0.4379 - accuracy: 0.8749 - val_loss: 1.2623 - val_accuracy: 0.8048\n",
      "Epoch 10/30\n",
      "154/154 [==============================] - 6s 40ms/step - loss: 0.3482 - accuracy: 0.8812 - val_loss: 2.4040 - val_accuracy: 0.6733\n",
      "Epoch 11/30\n",
      "154/154 [==============================] - 6s 39ms/step - loss: 0.2900 - accuracy: 0.8986 - val_loss: 1.4079 - val_accuracy: 0.7771\n",
      "Epoch 12/30\n",
      "154/154 [==============================] - 6s 41ms/step - loss: 0.2330 - accuracy: 0.9236 - val_loss: 1.9572 - val_accuracy: 0.6971\n",
      "Epoch 13/30\n",
      "154/154 [==============================] - 6s 39ms/step - loss: 0.2651 - accuracy: 0.9064 - val_loss: 1.3746 - val_accuracy: 0.7886\n",
      "Epoch 14/30\n",
      "154/154 [==============================] - 6s 38ms/step - loss: 0.3712 - accuracy: 0.8840 - val_loss: 1.4386 - val_accuracy: 0.8038\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train\n",
    "# validation_data=(X_valid, y_valid)\n",
    "# X_test, y_test\n",
    "history1 = model1.fit(X_train, y_train, validation_data=(X_valid, y_valid),\\\n",
    "           epochs=30, callbacks = [early_stopping_monitor1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 8ms/step - loss: 0.6729 - accuracy: 0.8562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6729249358177185, 0.8561905026435852]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8561904761904762\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred1, axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "print(np.sum(y_pred==y_true)/len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (Implementing a Simple Convolutional Neural Network Model Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(128,128,1)))\n",
    "model2.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model2.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model2.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor2 = EarlyStopping(patience=5)\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 38s 242ms/step - loss: 3.2888 - accuracy: 0.7388 - val_loss: 0.7084 - val_accuracy: 0.8314\n",
      "Epoch 2/30\n",
      " 73/154 [=============>................] - ETA: 17s - loss: 0.2547 - accuracy: 0.9204"
     ]
    }
   ],
   "source": [
    "# X_train, y_train\n",
    "# validation_data=(X_valid, y_valid)\n",
    "# X_test, y_test\n",
    "history2 = model2.fit(X_train, y_train, validation_data=(X_valid, y_valid),\\\n",
    "           epochs=30, callbacks = [early_stopping_monitor2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = np.argmax(y_pred2, axis=-1)\n",
    "y_true1 = np.argmax(y_test, axis=-1)\n",
    "print(np.sum(y_pred1==y_true1)/len(y_true1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Verifying LeNet-5 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Historical LeNet-5 Architecture\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(20, (5,5), activation='relu', padding = 'same', strides=1, input_shape = (128,128,1)))\n",
    "model3.add(MaxPool2D((2,2), strides=2))\n",
    "\n",
    "model3.add(Conv2D(50, (5,5), activation='relu', strides=1, padding = 'same'))\n",
    "model3.add(MaxPool2D((2,2), strides=2))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "\n",
    "model3.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history3 = model3.fit(X_train, y_train, epochs = 30, batch_size=32, \\\n",
    "                      validation_data = (X_valid, y_valid), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BatchNormalization and Dropout layer to previous model to maximize generalization or minimize overfitting\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model4.add(Conv2D(32,(3,3), input_shape=(128,128,1), activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model4.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "# Neural network\n",
    "\n",
    "model4.add(Dense(units= 252, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(units=252, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model4.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics= ['accuracy'])\n",
    "early_stopping_monitor = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 Implementing complex CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "model5 = Sequential()\n",
    "\n",
    "# Convolutional layer, Batch Normalization layer, and maxpool layer 1\n",
    "model5.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,1)))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 2\n",
    "model5.add(Conv2D(64,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 3\n",
    "model5.add(Conv2D(128,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 4\n",
    "model5.add(Conv2D(256,(3,3),activation='relu'))\n",
    "# model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model5.add(Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model5.add(Dense(512,activation='relu'))\n",
    "# model5.add(Dropout(0.25))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model5.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer=optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "early_stopping_monitor5 = EarlyStopping(patience=5)\n",
    "model5.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history5 = model5.fit(X_train, y_train, epochs = 30, batch_size=32, validation_data = (X_valid, y_valid), \\\n",
    "           callbacks = [early_stopping_monitor5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "model6 = Sequential()\n",
    "\n",
    "# Convolutional layer, Batch Normalization layer, and maxpool layer 1\n",
    "model6.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,1)))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 2\n",
    "model6.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 3\n",
    "model6.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 4\n",
    "model6.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model6.add(Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model6.add(Dense(512,activation='relu'))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "# Output layer with 4 neurons for 4 classes \n",
    "model6.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor6 = EarlyStopping(patience=5)\n",
    "model6.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history6 = model6.fit(X_train, y_train, epochs = 30, batch_size=32, validation_data = (X_valid, y_valid), \\\n",
    "           callbacks = [early_stopping_monitor6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = model6.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model7.add(Conv2D(64,(5,5), input_shape=(128,128, 1), padding='same', activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Convolutional layer 2\n",
    "model7.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model7.add(Conv2D(256,(5,5), padding='same', activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 4\n",
    "model7.add(Conv2D(512,(5,5), padding='same', activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model7.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "\n",
    "model7.add(Dense(units= 512, activation='relu'))\n",
    "model7.add(Dropout(0.2))\n",
    "\n",
    "model7.add(Dense(units=512, activation='relu'))\n",
    "model7.add(Dropout(0.2))\n",
    "\n",
    "model7.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor6 = EarlyStopping(patience=5)\n",
    "model7.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history7 = model7.fit(X_train, y_train, epochs = 30, batch_size=32, validation_data = (X_valid, y_valid), \\\n",
    "           callbacks = [early_stopping_monitor6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = model7.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(y_pred8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "def epoch_vs_progress(history_name, model_name):\n",
    "    fig, ax = plt.subplots(2,1, figsize=(12,8))\n",
    "    ax[0].plot(history_name.history['loss'], color='b', marker='o', label=\"Training loss\")\n",
    "    ax[0].plot(history_name.history['val_loss'], color='r', marker='o', label=\"validation loss\",axes =ax[0])\n",
    "    ax[0].set_title(f\"Epochs vs. Training and Validation Loss for {model_name}\")\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history_name.history['accuracy'], color='b', marker='o', label=\"Training accuracy\")\n",
    "    ax[1].plot(history_name.history['val_accuracy'], color='r',marker='o', label=\"Validation accuracy\")\n",
    "    ax[1].set_title(f\"Epochs vs. Training and Validation Accuracy for {model_name}\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n",
    "epoch_vs_progress(history7, 'model7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "# type(history1)\n",
    "# history1.history.items()\n",
    "plt.plot(history1.history['loss'], 'b', label='training loss')\n",
    "plt.plot(history1.history['val_loss'], 'r', label='validation loss')\n",
    "plt.xlabel('Epochs', )\n",
    "plt.ylabel('Validation score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['Glioma','Meningioma','NoTumor','Pituitary']\n",
    "def get_all_metrics(true_category, pred_category, model_name, history_name):\n",
    "    \"\"\"\n",
    "    Confusion matrix and model performance metric visualization\n",
    "    \"\"\"\n",
    "    labels = ['Glioma','Meningioma','NoTumor','Pituitary']\n",
    "    y_true = np.argmax(true_category, axis=-1)\n",
    "    y_pred = np.argmax(pred_category, axis=-1)\n",
    "    \n",
    "    print(f\"\\nMax. training accuracy for {model_name}: {max(history_name.history['accuracy'])*100:.2f}%\")\n",
    "    print(f\"Max. validation accuracy for {model_name}: {max(history_name.history['val_accuracy'])*100:.2f}%\")\n",
    "    \n",
    "    accuracy = np.sum(y_true == y_pred)/len(y_true)\n",
    "    print(f\"Test accuracy for {model_name}: {(accuracy*100):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\\n\", classification_report(y_true, y_pred))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred),xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=\"Greens\",alpha=0.7, ax=ax, linewidths=2,linecolor='gray',fmt='d')\n",
    "    fig.text(s=f'      Confusion Matrix for {model_name}',size=18,fontweight='bold',\n",
    "            fontname='monospace',color='g',y=0.92,x=0.28,alpha=0.7)\n",
    "    plt.savefig(f\"../Figures/Confusion_Matrix/{model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test1, y_pred1, 'model_1', history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test2, y_pred2, 'model_2', history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test3, y_pred3, 'model_3', history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test4, y_pred4, 'model_4', history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test5, y_pred5, 'model_5', history5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test6, y_pred6, 'model_6', history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_metrics(y_test7, y_pred7, 'model_7', history7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_progress(history7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "from keras.models import model_from_json\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=np.argmax(y_test, axis=-1), y_pred=np.argmax(y_pred1, axis=-1))\n",
    "cm_plot_labels = ['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=cm_plot_labels,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
    "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
    "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n",
    "\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(14,7))\n",
    "sns.heatmap(confusion_matrix(true_labels, pred_labels),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=colors_green,alpha=0.5,linewidths=2,linecolor=colors_dark[3],fmt='d')\n",
    "fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n",
    "            fontname='monospace',color='k',y=0.92,x=0.28,alpha=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for keras nodel\n",
    "train_img = []\n",
    "train_labels = []\n",
    "\n",
    "test_img = []\n",
    "test_labels = []\n",
    "\n",
    "path_train = ('/kaggle/input/brain-tumor-classification-mri/Training/')\n",
    "path_test = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\n",
    "img_size= 300\n",
    "\n",
    "for i in os.listdir(path_train):\n",
    "    for j in os.listdir(path_train+i):\n",
    "        train_img.append (cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size))) \n",
    "        train_labels.append(i)\n",
    "        \n",
    "for i in os.listdir(path_test):\n",
    "    for j in os.listdir(path_test+i):\n",
    "        test_img.append (cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size))) \n",
    "        test_labels.append(i)\n",
    "        \n",
    "train_img = (np.array(train_img))\n",
    "test_img = (np.array(test_img))\n",
    "train_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(train_labels)]\n",
    "test_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "result = 0\n",
    "model_evaluate = []\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    model.fit(train_dataset,\n",
    "             epochs = 10, batch_size=10,\n",
    "             validation_data = 0.0  \n",
    "             )\n",
    "    result = model.evaluate(test_dataset)\n",
    "    model_evaluate.append(result[1])\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "model = effnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "model = ...\n",
    "\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)  # using comic sans is strictly prohibited!\n",
    "visualkeras.layered_view(model, legend=True, font=font)  # font is optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/visualkeras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "'''\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "'''\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Individual predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/OIP.jpg', target_size = (512, 512)) # Cargamos la imagen con un tamaño igual a\n",
    "                                                                                           # los anteriores\n",
    "test_image = image.img_to_array(test_image) # Convertimos la imagen en un array\n",
    "test_image = np.expand_dims(test_image, axis = 0) # Modificamos las dimensions\n",
    "result = classifier.predict(test_image) # Prediccion\n",
    "print(training_dataset.class_indices)\n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "'''\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary 1: horizontalflip=True, (64,64)\n",
    "model 1=0.88 , model2=0.9419, model3=0.9695, model4=0.9771, model5=0.9629, model6=0.9695\n",
    "Summary 2: (64,64)\n",
    "model 1=0.8990 , model2=0.9333, model3=0.9600, model4=0.9610, model5=, model6=0.9533\n",
    "Summary 3: horizontalflip=True, (128,128)\n",
    "model 1=0.84 , model2=0.9162, model3=0.9790, model4=0.9657, model5=, model6=0.9552\n",
    "Summary 4: (128,128)\n",
    "model 1=0.92 , model2=0.9467, model3=0.9638, model4=0.8971, model5=, model6=0.9457"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
