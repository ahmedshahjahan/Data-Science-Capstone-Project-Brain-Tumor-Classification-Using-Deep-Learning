{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling (Brain Tumor Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os, sys, os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Dense, Flatten, AveragePooling2D, Conv2D, BatchNormalization, MaxPool2D, MaxPooling2D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generating the training, test, and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1078 images belonging to 4 classes.\n",
      "Found 519 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating Dataset using ImageDataGenerator\n",
    "# Using Cleaned Dataset\n",
    "# From \"../BrainTumorDataClean/\" directory\n",
    "\n",
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "validation = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "train_dataset = train.flow_from_directory(\"../BrainMRI1/Training\",\n",
    "                                          target_size=(200,200),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "\n",
    "validation_dataset = validation.flow_from_directory(\"../BrainMRI1/Validation\",\n",
    "                                          target_size=(200,200),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "\n",
    "test_dataset = test.flow_from_directory(\"../BrainMRI1/Testing\",\n",
    "                                          target_size=(200,200),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Glioma': 0, 'Meningioma': 1, 'NoTumor': 2, 'Pituitary': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label =next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, j in zip(img, label):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model 1 (Implementing a Simple Neural Network using  dense layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the Simple model using Dense Layer [optimizer = 'adam']\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(200,200,1)))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 4s 99ms/step - loss: 1.6143 - accuracy: 0.3349 - val_loss: 1.1825 - val_accuracy: 0.4644\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 3s 95ms/step - loss: 1.2072 - accuracy: 0.4879 - val_loss: 1.1306 - val_accuracy: 0.5067\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 3s 96ms/step - loss: 1.1186 - accuracy: 0.5056 - val_loss: 1.0660 - val_accuracy: 0.5414\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 3s 97ms/step - loss: 1.0117 - accuracy: 0.5668 - val_loss: 0.9872 - val_accuracy: 0.5973\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.9115 - accuracy: 0.6150 - val_loss: 0.9627 - val_accuracy: 0.5934\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 3s 96ms/step - loss: 0.8009 - accuracy: 0.6837 - val_loss: 0.8921 - val_accuracy: 0.6243\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 3s 97ms/step - loss: 0.6837 - accuracy: 0.7254 - val_loss: 0.9046 - val_accuracy: 0.6416\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.6328 - accuracy: 0.7514 - val_loss: 1.0990 - val_accuracy: 0.5337\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 3s 96ms/step - loss: 0.5320 - accuracy: 0.7857 - val_loss: 0.9594 - val_accuracy: 0.6089\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history1 = model1.fit(train_dataset, epochs = 20, batch_size=10, \\\n",
    "                      validation_data = validation_dataset, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "# type(history1)\n",
    "# history1.history.items()\n",
    "plt.plot(history1.history['loss'], 'b', label='training loss')\n",
    "plt.plot(history1.history['val_loss'], 'r', label='validation loss')\n",
    "plt.xlabel('Epochs', )\n",
    "plt.ylabel('Validation score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_dataset.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model 2 (Implementing a Simple Convolutional Neural Network Model Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model2 = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(200,200,1)),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 20s 588ms/step - loss: 1.2122 - accuracy: 0.4824 - val_loss: 1.0385 - val_accuracy: 0.5761\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 20s 599ms/step - loss: 0.9289 - accuracy: 0.6308 - val_loss: 0.8987 - val_accuracy: 0.5992\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 21s 621ms/step - loss: 0.7531 - accuracy: 0.7078 - val_loss: 0.8085 - val_accuracy: 0.6590\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 23s 686ms/step - loss: 0.6353 - accuracy: 0.7542 - val_loss: 0.7715 - val_accuracy: 0.6975\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 22s 662ms/step - loss: 0.5493 - accuracy: 0.7876 - val_loss: 0.7696 - val_accuracy: 0.6455\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 22s 663ms/step - loss: 0.5062 - accuracy: 0.8163 - val_loss: 0.7103 - val_accuracy: 0.7495\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 22s 657ms/step - loss: 0.4294 - accuracy: 0.8553 - val_loss: 0.6613 - val_accuracy: 0.7303\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 22s 642ms/step - loss: 0.3742 - accuracy: 0.8766 - val_loss: 0.6507 - val_accuracy: 0.7437\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 22s 635ms/step - loss: 0.3318 - accuracy: 0.9017 - val_loss: 0.6167 - val_accuracy: 0.7553\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 22s 639ms/step - loss: 0.3008 - accuracy: 0.9054 - val_loss: 0.6640 - val_accuracy: 0.7476\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 22s 636ms/step - loss: 0.2791 - accuracy: 0.9156 - val_loss: 0.6099 - val_accuracy: 0.7572\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 22s 642ms/step - loss: 0.2503 - accuracy: 0.9341 - val_loss: 0.6223 - val_accuracy: 0.7649\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 22s 640ms/step - loss: 0.2272 - accuracy: 0.9378 - val_loss: 0.6101 - val_accuracy: 0.7630\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 22s 635ms/step - loss: 0.1954 - accuracy: 0.9536 - val_loss: 0.5901 - val_accuracy: 0.7803\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 22s 636ms/step - loss: 0.1810 - accuracy: 0.9620 - val_loss: 0.6147 - val_accuracy: 0.7765\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 22s 642ms/step - loss: 0.1628 - accuracy: 0.9666 - val_loss: 0.5977 - val_accuracy: 0.7881\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 22s 662ms/step - loss: 0.1576 - accuracy: 0.9592 - val_loss: 0.6205 - val_accuracy: 0.7803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26747198370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=train_dataset,\n",
    "    steps_per_epoch=len(train_dataset),\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=len(validation_dataset),\n",
    "    epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 130ms/step - loss: 3.5296 - accuracy: 0.5508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5295772552490234, 0.5507614016532898]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =model2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_dataset.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 Implementing CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "# Convolutional layer, Batch Normalization layer, and maxpool layer 1\n",
    "model3.add(Conv2D(32,(3,3),activation='relu',input_shape=(200,200,1)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 2\n",
    "model3.add(Conv2D(64,(3,3),activation='relu'))\n",
    "# model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 3\n",
    "model3.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer,  Batch Normalization layer, and maxpool layer 4\n",
    "model3.add(Conv2D(256,(3,3),activation='relu'))\n",
    "# model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model3.add(Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model3.add(Dense(512,activation='relu'))\n",
    "# model3.add(Dropout(0.25))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model3.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model3.fit(train_dataset, epochs = 25, batch_size=32, validation_data = validation_dataset, callbacks = [early_stopping_monitor])\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model3.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((predictions2[:,0]>0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_dataset.classes, y_pred=np.argmax(predictions2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 (LeNet-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Historical LeNet-5 Architecture\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(20, (5,5), activation='relu', padding = 'same', strides=1, input_shape = (200,200,1)))\n",
    "model4.add(MaxPool2D((2,2), strides=2))\n",
    "model4.add(Conv2D(50, (5,5), activation='relu', strides=1, padding = 'same'))\n",
    "model4.add(MaxPool2D((2,2), strides=2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(512, activation='relu'))\n",
    "model4.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/sid321axn/regularization-techniques-in-deep-learning\n",
    "# kernel_regularizer=regularizers.l2(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 [==============================] - 31s 917ms/step - loss: 1.4596 - accuracy: 0.5111 - val_loss: 0.8573 - val_accuracy: 0.6551\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 32s 932ms/step - loss: 0.5924 - accuracy: 0.7801 - val_loss: 0.7034 - val_accuracy: 0.7283\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 32s 937ms/step - loss: 0.2899 - accuracy: 0.8989 - val_loss: 0.6574 - val_accuracy: 0.7495\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 32s 953ms/step - loss: 0.1279 - accuracy: 0.9555 - val_loss: 0.6886 - val_accuracy: 0.7823\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 33s 964ms/step - loss: 0.0707 - accuracy: 0.9750 - val_loss: 0.7656 - val_accuracy: 0.8015\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 34s 990ms/step - loss: 0.0305 - accuracy: 0.9907 - val_loss: 0.8474 - val_accuracy: 0.8015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26746d08e80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model4.fit(train_dataset, epochs = 50, batch_size=32, \\\n",
    "                      validation_data = validation_dataset, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(200,200,1)))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "model.add(Dense(units=84, activation='relu'))\n",
    "model.add(Dense(units=4, activation = 'softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs = 50, batch_size=32, \\\n",
    "                      validation_data = validation_dataset, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "# Convolutional layer 1\n",
    "model5.add(Conv2D(64,(7,7), input_shape=(32, 32, 1), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Convolutional layer 2\n",
    "model5.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model5.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 4\n",
    "model5.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    " # Convolutional layer 5\n",
    "model5.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 6\n",
    "model5.add(Conv2D(512,(7,7), padding='same', activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "# Full connect layers\n",
    "\n",
    "model5.add(Dense(units= 1024, activation='relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(units=512, activation='relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model5.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                   metrics= ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.fit(train_dataset, epochs=20, batch_size=32, validation_data = validation_dataset, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =model5.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "result = 0\n",
    "model_evaluate = []\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    model.fit(train_dataset,\n",
    "             epochs = 10, batch_size=10,\n",
    "             validation_data = 0.0  \n",
    "             )\n",
    "    result = model.evaluate(test_dataset)\n",
    "    model_evaluate.append(result[1])\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(model_evaluate)\n",
    "print(np.mean(model_evaluate))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for keras nodel\n",
    "train_img = []\n",
    "train_labels = []\n",
    "\n",
    "test_img = []\n",
    "test_labels = []\n",
    "\n",
    "path_train = ('/kaggle/input/brain-tumor-classification-mri/Training/')\n",
    "path_test = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\n",
    "img_size= 300\n",
    "\n",
    "for i in os.listdir(path_train):\n",
    "    for j in os.listdir(path_train+i):\n",
    "        train_img.append (cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size))) \n",
    "        train_labels.append(i)\n",
    "        \n",
    "for i in os.listdir(path_test):\n",
    "    for j in os.listdir(path_test+i):\n",
    "        test_img.append (cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size))) \n",
    "        test_labels.append(i)\n",
    "        \n",
    "train_img = (np.array(train_img))\n",
    "test_img = (np.array(test_img))\n",
    "train_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(train_labels)]\n",
    "test_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(test_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "from keras.models import model_from_json\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "model = effnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "model = ...\n",
    "\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)  # using comic sans is strictly prohibited!\n",
    "visualkeras.layered_view(model, legend=True, font=font)  # font is optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/visualkeras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "'''\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "'''\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Individual predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/OIP.jpg', target_size = (512, 512)) # Cargamos la imagen con un tamaño igual a\n",
    "                                                                                           # los anteriores\n",
    "test_image = image.img_to_array(test_image) # Convertimos la imagen en un array\n",
    "test_image = np.expand_dims(test_image, axis = 0) # Modificamos las dimensions\n",
    "result = classifier.predict(test_image) # Prediccion\n",
    "print(training_dataset.class_indices)\n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "'''\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rotation_range=90, zoom_range=0.2, \\\n",
    "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, rescale=1/255)\n",
    "test = ImageDataGenerator(rotation_range=90, zoom_range=0.2, \\\n",
    "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, rescale=1/255)\n",
    "validation = ImageDataGenerator(rotation_range=90, zoom_range=0.2, \\\n",
    "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, rescale=1/255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
