{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and EDA (Brain Tumor Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, sys\n",
    "import cv2\n",
    "import PIL\n",
    "import os.path\n",
    "from PIL import Image, ImageOps\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import color\n",
    "from skimage.filters import gaussian\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2, VGG16\n",
    "# from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimgimport seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../BrainMRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Testing', 'Training']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glioma_Tumor', 'Meningioma_Tumor', 'No_Tumor', 'Pituitary_Tumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path + \"/Training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glioma_Tumor', 'Meningioma_Tumor', 'No_Tumor', 'Pituitary_Tumor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path + \"/Testing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Glioma_Tumor','No_Tumor','Meningioma_Tumor','Pituitary_Tumor']\n",
    "\n",
    "class_map = {\n",
    "    'No_Tumor': 0,\n",
    "    'Glioma_Tumor': 1,\n",
    "    'Meningioma_Tumor': 2,\n",
    "    'Pituitary_Tumor': 3\n",
    "}\n",
    "\n",
    "inverse_class_map = {\n",
    "    0: 'No_Tumor',\n",
    "    1: 'Glioma_Tumor',\n",
    "    2: 'Meningioma_Tumor',\n",
    "    3: 'Pituitary_Tumor'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 300, 300\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 826/826 [00:01<00:00, 441.32it/s]\n",
      "100%|██████████| 395/395 [00:00<00:00, 527.61it/s]\n",
      "100%|██████████| 822/822 [00:01<00:00, 411.99it/s]\n",
      "100%|██████████| 827/827 [00:02<00:00, 388.66it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 477.85it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 1210.90it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 618.17it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 210.50it/s]\n"
     ]
    }
   ],
   "source": [
    "IMAGE = []\n",
    "LABELS = []\n",
    "\n",
    "for label in labels:\n",
    "    folderPath = os.path.join('../BrainMRI/Training', label)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath, j))\n",
    "        img = cv2.resize(img,(h, w))\n",
    "        IMAGE.append(img)\n",
    "        LABELS.append(class_map[label])\n",
    "            \n",
    "        \n",
    "for label in labels:\n",
    "    folderPath = os.path.join('../BrainMRI/Testing', label)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(h, w))\n",
    "        IMAGE.append(img)\n",
    "        LABELS.append(class_map[label])\n",
    "        \n",
    "X = np.array(IMAGE)\n",
    "y = np.array(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, to_categorical(y), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inspecting the Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "data_path = \"../BrainMRI/\"\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training subfolders\n",
    "os.listdir(data_path+'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing subfolders\n",
    "os.listdir(data_path+'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Directories\n",
    "glioma_path_tr = \"../BrainMRI/Training/Glioma_Tumor/\"\n",
    "notumor_path_tr = \"../BrainMRI/Training/No_Tumor/\"\n",
    "pituitary_path_tr = \"../BrainMRI/Training/Pituitary_Tumor/\"\n",
    "meningioma_path_tr = \"../BrainMRI/Training/Meningioma_Tumor/\"\n",
    "\n",
    "training_paths = [glioma_path_tr, pituitary_path_tr, meningioma_path_tr, notumor_path_tr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Directories\n",
    "glioma_path_te = \"../BrainMRI/Testing/Glioma_Tumor/\"\n",
    "notumor_path_te = \"../BrainMRI/Testing/No_Tumor/\"\n",
    "pituitary_path_te = \"../BrainMRI/Testing/Pituitary_Tumor/\"\n",
    "meningioma_path_te = \"../BrainMRI/Testing/Meningioma_Tumor/\"\n",
    "\n",
    "test_paths = [glioma_path_te, pituitary_path_te, meningioma_path_te, notumor_path_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspecting the Image File Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Image File Format other than [.jpg] for Training Set\n",
    "count = 0\n",
    "for path in training_paths:\n",
    "    list_images = os.listdir(path)\n",
    "    for i in list_images:\n",
    "        if i.split('.')[-1] != 'jpg':\n",
    "            count += 1\n",
    "            # print('Other Format Found')\n",
    "        else:\n",
    "            continue\n",
    "print(f'Other Than [.jpg]: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Image File Format other than [.jpg] for Testing Set\n",
    "count = 0\n",
    "for path in test_paths:\n",
    "    list_images = os.listdir(path)\n",
    "    for i in list_images:\n",
    "        if i.split('.')[-1] != 'jpg':\n",
    "            count += 1\n",
    "            #print('Other Format Found')\n",
    "        else:\n",
    "            continue\n",
    "print(f'Other Than [.jpg]: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualizing the Different Tumor Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing all different tumor types in training dataset and \n",
    "# The respective size of the images\n",
    "\n",
    "for path in training_paths:\n",
    "    list_images = os.listdir(path)\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(12,6))\n",
    "    for i in range(2):\n",
    "        # plt.figure()\n",
    "        array = plt.imread(os.path.join(path, list_images[i]))\n",
    "        ax[i].imshow(array)\n",
    "        if path.split('/')[-2] == 'NoTumor':\n",
    "            ax[i].set_title(path.split('/')[-2])\n",
    "        else:\n",
    "            ax[i].set_title(path.split('/')[-2]+' Tumor')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meningioma Tumor\n",
    "Meningioma is the most common primary brain tumor, accounting for more than 30% of all brain tumors. Meningiomas originate in the meninges, the outer three layers of tissue that cover and protect the brain just under the skull. Women are diagnosed with meningiomas more often than men. About 85% of meningiomas are noncancerous, slow-growing tumors. Almost all meningiomas are considered benign, but some meningiomas can be persistent and come back after treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pituitary Tumor\n",
    "A pituitary tumor is an abnormal growth in the pituitary gland. The pituitary is a small gland in the brain. It is located behind the back of the nose. It makes hormones that affect many other glands and many functions in your body. Most pituitary tumors are not cancerous (benign). They don’t spread to other parts of your body. But they can cause the pituitary to make too few or too many hormones, causing problems in the body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glioma Tumor:\n",
    "Gliomas are the most prevalent type of adult brain tumor, accounting for 78 percent of malignant brain tumors. They arise from the supporting cells of the brain, called the glia. These cells are subdivided into astrocytes, ependymal cells and oligodendroglial cells (or oligos). Glial tumors include the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Tumor\n",
    "There is no tumor present in the brain cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inspecting a Single RGB Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the size, shape, and data-type of a single image\n",
    "plt.figure(figsize=(6,6))\n",
    "image_array = plt.imread(\"../BrainMRI/Training/Glioma_Tumor/gg (1).jpg\")\n",
    "plt.imshow(image_array)\n",
    "plt.show()\n",
    "print(f\"Size :{image_array.size} \\nShape: {image_array.shape} \\nData Type: {image_array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspecting the different channels of the RGB image\n",
    "red_channel = image_array[:,:,0]\n",
    "green_channel = image_array[:,:,1]\n",
    "blue_channel = image_array[:,:,2]\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(12,4))\n",
    "ax[0].imshow(red_channel)\n",
    "ax[0].set_title('Red Channel')\n",
    "ax[1].imshow(green_channel)\n",
    "ax[1].set_title('Green Channel')\n",
    "ax[2].imshow(blue_channel)\n",
    "ax[2].set_title('Blue Channel')\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the green channel of the RGB Image using scipy.ndimage\n",
    "plt.figure(figsize=(12,8))\n",
    "hist = ndi.histogram(green_channel, min=0, max=255, bins=256)\n",
    "plt.plot(hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the histogram red channel of the RGB image using matplotlib.pyplot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(red_channel.ravel(), bins=256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gray scale of the RGB images\n",
    "plt.figure(figsize=(6,6))\n",
    "gray_image = color.rgb2gray(image_array)\n",
    "print(\"Shape:\", gray_image.shape)\n",
    "plt.imshow(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Filtering, Sharpening, Manually Segmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing Sharpness using filter\n",
    "gaussian_image = gaussian(gray_image, multichannel=True)\n",
    "\n",
    "# Show original and resulting image to compare\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,8))\n",
    "ax[0].imshow(gray_image)\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(gaussian_image)\n",
    "ax[1].set_title('Reduced sharpness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original image looks better quality than filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth \"im\" with Gaussian filters\n",
    "im_s1 = ndi.gaussian_filter(gray_image, sigma=1)\n",
    "im_s3 = ndi.gaussian_filter(gray_image, sigma=3)\n",
    "\n",
    "# Draw bone masks of each image\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,10))\n",
    "axes[0].imshow(gray_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[1].imshow(im_s1)\n",
    "axes[1].set_title(\"Sharpen Image: sigma=1\")\n",
    "axes[2].imshow(im_s3)\n",
    "axes[2].set_title(\"Sharpen Image: sigma=3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original image looks better quality than sharpen image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to manually segment and visualize the tumor area inside the head\n",
    "plt.figure(figsize=(6,6))\n",
    "# plt.imshow(gray>0.37)\n",
    "# plt.imshow(array)\n",
    "plt.imshow(image_array[:,:,0]>90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Counting the total number of training, testing, and validation images and locating any grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Gray Scale images in training datasets\n",
    "train_count = 0\n",
    "gray_count = 0\n",
    "for path in training_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img_name))\n",
    "        try:\n",
    "            channel = img_array.shape[2]\n",
    "            if channel != 3:\n",
    "                gray_count += 1\n",
    "            else:\n",
    "                train_count += 1\n",
    "        except:\n",
    "            pass\n",
    "print(f\"Total Grayscale Images: {gray_count}\")\n",
    "print(f'Total Training Images: {train_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Gray Scale images in testing datasets\n",
    "test_count = 0\n",
    "gray_count = 0\n",
    "\n",
    "for path in test_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img_name))\n",
    "        try:\n",
    "            channel = img_array.shape[2]\n",
    "            if channel != 3:\n",
    "                gray_count += 1\n",
    "            else:\n",
    "                test_count += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "print(f\"Grayscale Images Found: {gray_count}\")\n",
    "print(f'Total Test Images: {test_count}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the shape of the images in trainig, testing, and validation sub folders its visible that there is no gray scale images and all of the images are color image (RGB). There are 4956 trainig images, 1194 testing images, and 873 validation images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Inspecting the height and width of the images in each training, testing, and validation subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the image shape of each training subfolders before cropping and resizing\n",
    "\n",
    "base_HW = 512\n",
    "min_height = 512\n",
    "min_width = 512\n",
    "max_height = 512\n",
    "max_width = 512\n",
    "count = 0\n",
    "\n",
    "for path in training_paths:\n",
    "    \n",
    "    for img_name in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img_name))\n",
    "        height, width, channel = img_array.shape\n",
    "        \n",
    "        if (height == base_HW) and (width == base_HW) and (channel == 3):\n",
    "            continue\n",
    "            \n",
    "        elif ((height < base_HW) or (width < base_HW)) and ((height < min_height) or (width < min_width)):\n",
    "            # print(f\"{os.path.join(path, img_name)}\")\n",
    "            min_height = height\n",
    "            min_width = width\n",
    "            count += 1\n",
    "            \n",
    "        elif ((height > base_HW) or (width > base_HW)) and ((height > max_height) or (width > max_width)):\n",
    "            # print(f\"{os.path.join(path, img_name)}\")\n",
    "            max_height = height\n",
    "            max_width = width\n",
    "            count += 1\n",
    "            \n",
    "print(f\"\\nDifferent Shape Count: {count} \\nMin Height: {min_height}, Min Width: {min_width} \\\n",
    "      \\nMax Height: {max_height}, Max Width {max_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the images have a shape of (512, 512, 3). There are 299 training images that does not contain the same height and width or in other words they contain different shape than (512, 512). So, We need to resize the images in respective subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the image shape of each testing subfolders before cropping and resizing\n",
    "\n",
    "base_hw = 512\n",
    "min_height = 512\n",
    "min_width = 512\n",
    "max_height = 512\n",
    "max_width = 512\n",
    "count = 0\n",
    "\n",
    "for path in test_paths:\n",
    "    \n",
    "    for img_name in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img_name))\n",
    "        height, width, channel = img_array.shape\n",
    "        \n",
    "        if (height == base_hw) and (width == base_hw) and (channel == 3):\n",
    "            continue\n",
    "            \n",
    "        elif ((height < base_HW) or (width < base_HW)) and ((height < min_height) or (width < min_width)):\n",
    "            # print(f\"{os.path.join(path, img_name)}\")\n",
    "            min_height = height\n",
    "            min_width = width\n",
    "            count += 1\n",
    "            \n",
    "        elif ((height > base_HW) or (width > base_HW)) and ((height > max_height) or (width > max_width)):\n",
    "            # print(f\"{os.path.join(path, img_name)}\")\n",
    "            max_height = height\n",
    "            max_width = width\n",
    "            count += 1\n",
    "            \n",
    "print(f\"\\nDifferent Shape Count: {count} \\nMin Height: {min_height}, Min Width: {min_width} \\\n",
    "      \\nMax Height: {max_height}, Max Width {max_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the images have a shape of (512, 512, 3). There are 196 test images that does not contain the same height and width or in other words they contain different shape than (512, 512). So, We need to resize the images in respective subfolders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Resizing, rgb to grayscale conversion, and save them to a new directory for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Training Directories\n",
    "new_glioma_path_tr = \"../BrainMRI_New/Training/Glioma_Tumor/\"\n",
    "new_notumor_path_tr = \"../BrainMRI_New/Training/No_Tumor/\"\n",
    "new_pituitary_path_tr = \"../BrainMRI_New/Training/Pituitary_Tumor/\"\n",
    "new_meningioma_path_tr = \"../BrainMRI_New/Training/Meningioma_Tumor/\"\n",
    "\n",
    "new_training_paths = [new_glioma_path_tr, new_pituitary_path_tr, new_meningioma_path_tr, new_notumor_path_tr]\n",
    "\n",
    "# New Test Directories\n",
    "new_glioma_path_te = \"../BrainMRI_New/Testing/Glioma_Tumor/\"\n",
    "new_notumor_path_te = \"../BrainMRI_New/Testing/No_Tumor/\"\n",
    "new_pituitary_path_te = \"../BrainMRI_New/Testing/Pituitary_Tumor/\"\n",
    "new_meningioma_path_te = \"../BrainMRI_New/Testing/Meningioma_Tumor/\"\n",
    "\n",
    "new_test_paths = [new_glioma_path_te, new_pituitary_path_te, new_meningioma_path_te, new_notumor_path_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "# rgb to gray conversion\n",
    "# resizing into (300, 300)\n",
    "\n",
    "for path, new_path in zip(training_paths, new_training_paths):\n",
    "    \n",
    "    for img_name in os.listdir(path):\n",
    "        \n",
    "        if os.path.isfile(path+img_name):\n",
    "        \n",
    "            old_dir = path+img_name\n",
    "            new_dir = new_path+img_name\n",
    "            img = Image.open(old_dir)\n",
    "            \n",
    "            try:\n",
    "                img_gray = ImageOps.grayscale(img)\n",
    "                resized_gray = img_gray.resize((300,300), PIL.Image.ANTIALIAS)\n",
    "                resized_gray.save(new_dir, quality=95)\n",
    "            except ValueError:\n",
    "                print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "# rgb to gray conversion\n",
    "# resizing into (300, 300)\n",
    "\n",
    "for path, new_path in zip(test_paths, new_test_paths):\n",
    "    \n",
    "    for img_name in os.listdir(path):\n",
    "        \n",
    "        if os.path.isfile(path+img_name):\n",
    "        \n",
    "            old_dir = path+img_name\n",
    "            new_dir = new_path+img_name\n",
    "            img = Image.open(old_dir)\n",
    "            \n",
    "            try:\n",
    "                img_gray = ImageOps.grayscale(img)\n",
    "                resized_gray = img_gray.resize((300,300), PIL.Image.ANTIALIAS)\n",
    "                resized_gray.save(new_dir, quality=95)\n",
    "            except ValueError:\n",
    "                print(\"There is something wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Inspecting the new resized and grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the new images of different class in test datasets\n",
    "\n",
    "for path in new_test_paths:\n",
    "    list_images = os.listdir(path)\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(12,6))\n",
    "    for i in range(2):\n",
    "        # plt.figure()\n",
    "        array = plt.imread(os.path.join(path, list_images[i]))\n",
    "        ax[i].imshow(array)\n",
    "        if path.split('/')[-2] == 'NoTumor':\n",
    "            ax[i].set_title(path.split('/')[-2])\n",
    "        else:\n",
    "            ax[i].set_title(path.split('/')[-2]+' Tumor')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 4) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fac680b9018a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhistory1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 4) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Specify the Simple model using Dense Layer [optimizer = 'adam']\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(300,300,3)))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history1 = model1.fit((X_train, y_train), epochs = 20, batch_size=10, validation_data = ImageDataGenerator(1./255).flow((X_test, y_test)), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "\n",
    "# Convolutional layer and maxpool layer 1\n",
    "model2.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(300,300,1)))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 2\n",
    "model2.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 3\n",
    "model2.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 4\n",
    "model2.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model2.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model2.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model2.add(keras.layers.Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "train_dataset = datagen.flow_from_directory(\"../BrainMRI/Training\", target_size=(300,300), batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "test_dataset  = datagen.flow_from_directory(\"../BrainMRI/Testing\", target_size=(300,300), batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2.fit(train_dataset, epochs = 15, batch_size=32, validation_data = test_dataset, callbacks = [early_stopping_monitor])\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = MobileNet(\n",
    "#     input_shape=(h, w, 3), \n",
    "#     weights='imagenet',\n",
    "#     include_top=False, \n",
    "#     pooling='avg'\n",
    "# )\n",
    "\n",
    "base_model = VGG16(\n",
    "    input_shape=(h, w, 3), \n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "output_class = 4\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(output_class, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n",
    "                    steps_per_epoch = len(X_train) / batch_size, epochs = epochs, callbacks = EarlyStopping(patience=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
